{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Interactive Session: Complementing anthropogenic GHG emissions with natural GHG emissions and fluxes\"\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About the Data\n",
    "\n",
    "Methane (CH₄) emissions from wetlands are estimated to be the largest natural source of methane in the global CH₄ budget, contributing to roughly one third of the total of natural and anthropogenic emissions. Wetland CH₄ is produced by microbes breaking down organic matter in the oxygen deprived environment of inundated soils. Due to limited data availability, the details of the role of wetland CH₄ emissions has thus far been underrepresented. Using the Wald Schnee und Landschaft version (LPJ-wsl) of the Lund-Potsdam-Jena Dynamic Global Vegetation Model (LPJ-DGVM) global CH₄ emissions from wetlands are estimated at 0.5 x 0.5 degree resolution by simulating wetland extent and using characteristics of these inundated areas, such as soil moisture, temperature, and carbon content, to estimate CH₄ quantities emitted into the atmosphere. Highlighted areas displayed in this dataset show concentrated methane sources from tropical and high latitude ecosystems. The LPJ-wsl Wetland Methane Emissions data product presented here consists of global daily and monthly model estimates of terrestrial wetland CH₄ emissions from 1980 - 2021. These data are regularly used in conjunction with National Aeronautics and Space Administration’s (NASA) Goddard Earth Observing System (GEOS) model to simulate the impact of wetlands and other methane sources on atmospheric methane concentrations, to compare against satellite and airborne data, and to improve understanding and prediction of wetland emissions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirements\n",
    "- Set up Python Environment - See setup_instructions.md in the `/setup/` folder"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Objectives\n",
    "- How to use `U.S. GHG Center STAC Catalog` to access `Wetland Methane Emissions, LPJ-wsl Model` data\n",
    "- How to use `earthaccess` to find MERRA-2 data\n",
    "- How to visualize datasets using `folium` and perform zonal statistics\n",
    "- How to plot time series for `MERRA-2` variables and `Wetland Methane Emissions, LPJ-wsl Model` and analyze the results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach\n",
    "\n",
    "1. Identify available dates and temporal frequency of observations for the given collection using the GHGC API `/stac `endpoint. The collection processed in this notebook is the Wetland Methane Emissions, LPJ-wsl Model data product\n",
    "2. Pass the STAC item into the raster API `/stac/tilejson.json` endpoint\n",
    "3. Access the MERRA-2 data for different variables (precipitation rate, surface soil moisture)\n",
    "4. Define the spatial region of interest\n",
    "5. Using plugins from `folium` to visualize two tiles (side-by-side), allowing time point comparison\n",
    "6. After the visualization, perform zonal statistics for a given polygon\n",
    "7. Plot monthly time series for LPJ-wetland emission and different MERRA-2 dataset and analyze them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "1. Monthly LPJ Wetland CH4 Emissions (U.S.GHG Center STAC)\n",
    "2. Monthly MERRA-2 Precipitation RateDataset: MERRA2_400.tavgM_2d_flx_Nx\n",
    "Variable: `PRECTOT`\n",
    "https://disc.gsfc.nasa.gov/datasets/M2TMNXFLX_5.12.4/summary\n",
    "\n",
    "3. Monthly MERRA-2 Surface Soil MoistureDataset: MERRA2_400.tavgM_2d_lnd_Nx\n",
    "Variable: `SFMC`\n",
    "Long-term mean variable: `GWETTOP`\n",
    "https://disc.gsfc.nasa.gov/datasets/M2TMNXLND_5.12.4/summary\n",
    "\n",
    "4. Monthly MERRA-2 T2MDataset: MERRA2_400.instM_2d_asm_Nx\n",
    "Variable: `T2M`\n",
    "https://disc.gsfc.nasa.gov/datasets/M2IMNXASM_5.12.4/summary\n",
    "\n",
    "5. MERRA-2 Long-Term MeansMERRA2.tavgC_2d_ltm_Nx\n",
    "https://disc.gsfc.nasa.gov/datasets/M2TCNXLTM_1/summary"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "Import the required Python libraries by running the next cell. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import earthaccess\n",
    "import os\n",
    "import warnings\n",
    "import requests\n",
    "import pandas as pd\n",
    "os.environ['USE_PYGEOS'] = '0'\n",
    "import geopandas\n",
    "import folium\n",
    "import folium.plugins\n",
    "import seaborn as sns\n",
    "import glob\n",
    "import numpy as np\n",
    "import netCDF4 as nc\n",
    "import matplotlib.pyplot as plt\n",
    "import branca.colormap as cm\n",
    "\n",
    "from folium import Map, TileLayer \n",
    "from branca.element import Figure\n",
    "from pystac_client import Client \n",
    "from pyproj import Geod\n",
    "from shapely import wkt\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NASA Earth Data Login Credentials\n",
    "To download or stream NASA data you will need an Earthdata account, you can create one here <https://urs.earthdata.nasa.gov/home>. We will use the `login` function from the `earthaccess` library for authentication before downloading at the end of the notebook. This function can also be used to create a local `.netrc` file if it doesn’t exist or add your login info to an existing `.netrc` file. If no Earthdata Login credentials are found in the `.netrc` you’ll be prompted for them. This step is not necessary to conduct searches but is needed to download or stream data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from netrc import netrc\n",
    "# from subprocess import Popen\n",
    "# from platform import system\n",
    "# from getpass import getpass\n",
    "# import os\n",
    "# import requests\n",
    "# import xarray as xr\n",
    "# import s3fs\n",
    "# import boto3\n",
    "# import cartopy.crs as ccrs\n",
    "# import cartopy.feature as cfeature\n",
    "# import matplotlib.pyplot as plt\n",
    "# import warnings\n",
    "# from IPython.display import display, Markdown\n",
    "\n",
    "# if (boto3.client('s3').meta.region_name == 'us-west-2'):\n",
    "#     display(Markdown('### us-west-2 Region Check: &#x2705;'))\n",
    "# else:\n",
    "#     display(Markdown('### us-west-2 Region Check: &#10060;'))\n",
    "#     raise ValueError('Your notebook is not running inside the AWS us-west-2 region, and will not be able to directly access NASA Earthdata S3 buckets')\n",
    "\n",
    "# urs = 'urs.earthdata.nasa.gov'    # Earthdata URL endpoint for authentication\n",
    "# prompts = ['Enter NASA Earthdata Login Username: ',\n",
    "#            'Enter NASA Earthdata Login Password: ']\n",
    "\n",
    "# netrc_name = \".netrc\"\n",
    "\n",
    "# # Determine if netrc file exists, and if so, if it includes NASA Earthdata Login Credentials\n",
    "# try:\n",
    "#     netrcDir = os.path.expanduser(f\"~/{netrc_name}\")\n",
    "#     # Check credentials against URS, and if username exists\n",
    "#     netrc(netrcDir).authenticators(urs)[0]\n",
    "\n",
    "# # Below, create a netrc file and prompt user for NASA Earthdata Login Username and Password\n",
    "# except FileNotFoundError:\n",
    "#     homeDir = os.path.expanduser(\"~\")\n",
    "#     Popen('touch {0}{2} | echo machine {1} >> {0}{2}'.format(homeDir + os.sep, urs, netrc_name), shell=True)\n",
    "#     Popen('echo login {} >> {}{}'.format(getpass(prompt=prompts[0]), homeDir + os.sep, netrc_name), shell=True)\n",
    "#     Popen('echo \\'password {} \\'>> {}{}'.format(getpass(prompt=prompts[1]), homeDir + os.sep, netrc_name), shell=True)\n",
    "#     # Set restrictive permissions\n",
    "#     Popen('chmod 0600 {0}{1}'.format(homeDir + os.sep, netrc_name), shell=True)\n",
    "\n",
    "# gesdisc_s3 = \"https://data.gesdisc.earthdata.nasa.gov/s3credentials\"\n",
    "\n",
    "# # Define a function for S3 access credentials\n",
    "\n",
    "# def begin_s3_direct_access(url: str=gesdisc_s3):\n",
    "#     response = requests.get(url).json()\n",
    "#     return s3fs.S3FileSystem(key=response['accessKeyId'],\n",
    "#                              secret=response['secretAccessKey'],\n",
    "#                              token=response['sessionToken'],\n",
    "#                              client_kwargs={'region_name':'us-west-2'})\n",
    "\n",
    "# fs = begin_s3_direct_access()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fn = 's3://gesdisc-cumulus-prod-protected/MERRA2/M2T1NXSLV.5.12.4/2019/03/MERRA2_400.tavg1_2d_slv_Nx.20190313.nc4'\n",
    "\n",
    "# fs.info(fn)\n",
    "# fs.ls('s3://gesdisc-cumulus-prod-protected/MERRA2/')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Querying the STAC API\n",
    "Search for the LPJ Wetland Methane Emissions Data using the Raster API and its STAC collection name!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provide STAC and RASTER API endpoints\n",
    "STAC_API_URL = \"http://ghg.center/api/stac\"\n",
    "RASTER_API_URL = \"https://ghg.center/api/raster\"\n",
    "\n",
    "\n",
    "# Please use the collection name similar to the one used in STAC collection\n",
    "# Name of the collection for wetland methane monthly emissions \n",
    "collection_name = \"lpjwsl-wetlandch4-monthgrid-v1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetching the collection from STAC collections using appropriate endpoint\n",
    "# The 'requests' library allows a HTTP request possible\n",
    "collection = requests.get(f\"{STAC_API_URL}/collections/{collection_name}\").json()\n",
    "collection"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are examining the contents of our `collection` under `summaries`. We notice the data is available from January 1980 to May 2021. By looking at `dashboard: time density`, we can see that these observations are collected monthly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function that would search for the number of items in above data collection in the STAC API\n",
    "def get_item_count(collection_id):\n",
    "    count = 0\n",
    "    items_url = f\"{STAC_API_URL}/collections/{collection_id}/items\"\n",
    "\n",
    "    while True:\n",
    "        response = requests.get(items_url)\n",
    "\n",
    "        if not response.ok:\n",
    "            print(\"error getting items\")\n",
    "            exit()\n",
    "\n",
    "        stac = response.json()\n",
    "        count += int(stac[\"context\"].get(\"returned\", 0))\n",
    "        next = [link for link in stac[\"links\"] if link[\"rel\"] == \"next\"]\n",
    "\n",
    "        if not next:\n",
    "            break\n",
    "        items_url = next[0][\"href\"]\n",
    "\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check total number of items available\n",
    "number_of_items = get_item_count(collection_name)\n",
    "items = requests.get(f\"{STAC_API_URL}/collections/{collection_name}/items?limit={number_of_items}\").json()[\"features\"]\n",
    "print(f\"Found {len(items)} items\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examining the first item in the collection\n",
    "# Keep in mind that a list starts from 0, 1, 2,... therefore ‘[0]’ is referring to the first item in the list/collection \n",
    "items[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we enter minimum and maximum values to provide our upper and lower bounds in 'rescale_values.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search for MERRA-2 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = f\"{os.getenv('HOME')}/shared/data/use-case-2\"   \n",
    "merra_t2m_dir=f'{data_dir}/merra_t2m_dir/'\n",
    "merra_soil_moisture_dir = f'{data_dir}/merra_soil_moisture_dir/'\n",
    "merra_precip_rate_dir = f'{data_dir}/merra_precip_rate_dir/'\n",
    "merra_t2m_clim_dir = f'{data_dir}/merra_t2m_clim_dir/'\n",
    "\n",
    "merra_precip_rate_clim_dir = merra_t2m_clim_dir \n",
    "merra_soil_moisture_clim_dir = merra_t2m_clim_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the Spatial Region of Interest\n",
    "For this example, our spatial region of interest (ROI) will be a region in the state of Louisiana (LA). In this example, we will create a rectangular ROI. The state of Louisiana encompasses a diverse range of non-tidal and tidal freshwater wetlands including palustrine, lacustrine, riverine, estuarine, and marine wetlands. These ecosystems cover roughly one-third of the state according to the [U.S. Fish and Wildlife Service](https://www.fws.gov/wetlands/data/Water-Summary-Reports/National-Water-Summary-Wetland-Resources-Louisiana.pdf), making Louisiana an ideal site for monitoring the natural source of methane emissions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create a area of interest (polygon) on which will be used later \n",
    "\n",
    "boundaries={\n",
    "    'Global':[-180,180,-90,90],\n",
    "    'Louisiana': [-95.9,-87.50,28.7,33.5],\n",
    "    'CONUS':[-127.08,-63.87,23.55,49.19],   #   conus\n",
    "    'Florida':[-84.07,-79.14,24.85,30.5],\n",
    "    'Northeast':[-74.88,-69.81,40.48,42.88]\n",
    "}\n",
    "focus = 'Louisiana'\n",
    "\n",
    "aoi = boundaries[focus]\n",
    "louisiana_aoi = {\n",
    "    \"type\": \"Feature\",\n",
    "    \"properties\": {},\n",
    "    \"geometry\": {\n",
    "        \"coordinates\": [\n",
    "            [\n",
    "                [aoi[0], aoi[2]], # SW Bounding Coordinate\n",
    "                [aoi[0], aoi[3]], # NW Bounding Coordinate\n",
    "                [aoi[1], aoi[3]], # NE Bounding Coordinate\n",
    "                [aoi[1],aoi[2]],  # SE Bounding Coordinate\n",
    "                [aoi[0], aoi[2]]  # Closing the polygon at the SW Bounding Coordinate\n",
    "            ]\n",
    "        ],\n",
    "        \"type\": \"Polygon\",\n",
    "    },\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Opening and Exploring Wetland Methane Emissions Data Using the Raster API\n",
    "\n",
    "In this notebook, we will explore the temporal impacts of methane emissions. We will visualize the outputs on a map using `folium`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To access the year value from each item more easily, this will let us query more explicitly by year and month (e.g., 2020-02)\n",
    "items = {item[\"properties\"][\"datetime\"][:7]: item for item in items} \n",
    "\n",
    "\n",
    "# Set the asset value to the appropriate parameter \n",
    "asset_name = 'ch4-wetlands-emissions'\n",
    "\n",
    "\n",
    "# Set the minimum and maximum values to provide our upper and lower bounds\n",
    "rescale_values = {'max': 2.0, 'min': 0.0}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will pass the item id, collection name, and `rescaling_factor` to the `Raster API` endpoint. We will do this twice, once for May 2020 and again for May 2021, so we can visualize each event independently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a colormap for the granule\n",
    "# Please refer to matplotlib library if you'd prefer choosing a different color ramp (https://matplotlib.org/stable/users/explain/colors/colormaps.html)\n",
    "color_map = \"magma\" \n",
    "\n",
    "\n",
    "date1, date2 = '2020-05', '2021-05'\n",
    "\n",
    "# May 2020 tile\n",
    "tile_1 = requests.get(\n",
    "    f\"{RASTER_API_URL}/stac/tilejson.json?collection={items[date1]['collection']}&item={items[date1]['id']}\"\n",
    "    \"&assets=ch4-wetlands-emissions\"\n",
    "    f\"&color_formula=gamma+r+1.05&colormap_name={color_map}\"\n",
    "    f\"&rescale={rescale_values['min']},{rescale_values['max']}\"\n",
    ").json()\n",
    "tile_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# May 2021 tile\n",
    "tile_2 = requests.get(\n",
    "    f\"{RASTER_API_URL}/stac/tilejson.json?collection={items[date2]['collection']}&item={items[date2]['id']}\"\n",
    "    \"&assets=ch4-wetlands-emissions\"\n",
    "    f\"&color_formula=gamma+r+1.05&colormap_name={color_map}\"\n",
    "    f\"&rescale={rescale_values['min']},{rescale_values['max']}\", \n",
    ").json()\n",
    "tile_2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing CH₄ Emissions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will import folium to map and folium.plugins to allow side-by-side mapping\n",
    "# Set initial zoom and center of map for CH₄ Layer\n",
    "# Centre of map [latitude,longitude]\n",
    "from folium.plugins import MousePosition\n",
    "map_ = folium.Map(location=(30,-90), zoom_start=6)\n",
    "\n",
    "\n",
    "# Use the 'TileLayer' library to display the raster layers and adjust the transparency of the layers on the map\n",
    "# May 2020\n",
    "vis_tile_1 = TileLayer(\n",
    "    tiles=tile_1[\"tiles\"][0],\n",
    "    attr=\"GHG\",\n",
    "    opacity=0.5,\n",
    ")\n",
    "\n",
    "\n",
    "# May 2021\n",
    "vis_tile_2 = TileLayer(\n",
    "    tiles=tile_2[\"tiles\"][0],\n",
    "    attr=\"GHG\",\n",
    "    opacity=0.5,\n",
    ")\n",
    "\n",
    "\n",
    "# Use the SideBySideLayers plugin to compare two layers on the same map\n",
    "sbs = folium.plugins.SideBySideLayers(layer_left=vis_tile_1, layer_right=vis_tile_2)\n",
    "vis_tile_1.add_to(map_)\n",
    "vis_tile_2.add_to(map_)\n",
    "\n",
    "\n",
    "# Load the GeoJSON file representing the state of Louisiana\n",
    "folium.GeoJson(louisiana_aoi, name=\"louisiana, USA\").add_to(map_)\n",
    "sbs.add_to(map_)\n",
    "MousePosition().add_to(map_)\n",
    "\n",
    "\n",
    "# Visualizing the map\n",
    "map_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will import folium to map and folium.plugins to add multiple tiles with layer control\n",
    "# Defining the breaks in the colormap \n",
    "colormap = cm.LinearColormap(colors = ['#2c115f','#721f81','#b73779','#f1605d','#feb078'], vmin = 0, vmax = 2 )\n",
    "\n",
    "\n",
    "# Add an appropriate caption, in this case it would be gragu of methane per meter squared per day\n",
    "colormap.caption = 'g CH₄/m²/day'\n",
    "\n",
    "\n",
    "new_date1, new_date2, new_date3 = '2021-05', '2021-06','2021-07'\n",
    "# Reading the tiles from raster api\n",
    "tile_date_1 = requests.get(\n",
    "    f\"{RASTER_API_URL}/stac/tilejson.json?collection={items[new_date1]['collection']}&item={items[new_date1]['id']}\"\n",
    "    \"&assets=ch4-wetlands-emissions\"\n",
    "    f\"&color_formula=gamma+r+1.05&colormap_name={color_map}\"\n",
    "    f\"&rescale={rescale_values['min']},{rescale_values['max']}\", \n",
    ").json()\n",
    "tile_date_1\n",
    "\n",
    "\n",
    "tile_date_2 = requests.get(\n",
    "    f\"{RASTER_API_URL}/stac/tilejson.json?collection={items[new_date2]['collection']}&item={items[new_date2]['id']}\"\n",
    "    \"&assets=ch4-wetlands-emissions\"\n",
    "    f\"&color_formula=gamma+r+1.05&colormap_name={color_map}\"\n",
    "    f\"&rescale={rescale_values['min']},{rescale_values['max']}\", \n",
    ").json()\n",
    "tile_date_2\n",
    "\n",
    "\n",
    "tile_date_3 = requests.get(\n",
    "    f\"{RASTER_API_URL}/stac/tilejson.json?collection={items[new_date3]['collection']}&item={items[new_date3]['id']}\"\n",
    "    \"&assets=ch4-wetlands-emissions\"\n",
    "    f\"&color_formula=gamma+r+1.05&colormap_name={color_map}\"\n",
    "    f\"&rescale={rescale_values['min']},{rescale_values['max']}\", \n",
    ").json()\n",
    "tile_date_3\n",
    "\n",
    "\n",
    "# Interactive visulaization \n",
    "map_ = folium.Map(location=(30,-90), zoom_start=5)\n",
    "\n",
    "# May 2021\n",
    "tile1 = TileLayer(\n",
    "    tiles=tile_date_1[\"tiles\"][0],\n",
    "    attr=\"GHG\",\n",
    "    opacity=0.8,\n",
    "    name=new_date1\n",
    ")\n",
    "tile1.add_to(map_)\n",
    "\n",
    "# June 2021\n",
    "tile2 = TileLayer(\n",
    "    tiles=tile_date_2[\"tiles\"][0],\n",
    "    attr=\"GHG\",\n",
    "    opacity=0.8,\n",
    "    name=new_date2\n",
    ")\n",
    "tile2.add_to(map_)\n",
    "\n",
    "# July 2021\n",
    "tile3 = TileLayer(\n",
    "    tiles=tile_date_3[\"tiles\"][0],\n",
    "    attr=\"GHG\",\n",
    "    opacity=0.8,\n",
    "    name=new_date3\n",
    ")\n",
    "tile3.add_to(map_)\n",
    "\n",
    "folium.GeoJson(louisiana_aoi, name=\"louisiana, USA\").add_to(map_)\n",
    "folium.LayerControl(collapsed=False,position='bottomleft').add_to(map_)\n",
    "\n",
    "svg_style = '<style>svg#legend {font-size: 14px; background-color: white;}</style>'\n",
    "map_.get_root().header.add_child(folium.Element(svg_style))\n",
    "map_.add_child(colormap)\n",
    "\n",
    "\n",
    "# Visualizing the map\n",
    "map_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Opening and Exploring MERRA-2 Data \n",
    "\n",
    "In this notebook, we will explore the MERRA-2 data. We will visualize the outputs on a map using `folium`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch the MERRA-2 collection from STAC collections using the appropriate endpoint\n",
    "items = requests.get(f\"{STAC_API_URL}/collections/{collection_name}/items?limit={number_of_items}\").json()[\"features\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## visualize MERRA-2\n",
    "# [-95.9,-87.50,28.7,33.5]\n",
    "\n",
    "\n",
    "# Insert the path to the NetCDF file\n",
    "file_path = f'{data_dir}/merra_t2m_dir/MERRA2_100.instM_2d_asm_Nx.199101.nc4'  # Replace with the path to your NetCDF file\n",
    "dataset = nc.Dataset(file_path)\n",
    "\n",
    "\n",
    "# Access coordinates (if needed)\n",
    "latitude = dataset.variables['lat'][:]\n",
    "longitude = dataset.variables['lon'][:]\n",
    "\n",
    "\n",
    "# Access variables\n",
    "variable_name = 'T2M'  # Replace with the variable you want to plot\n",
    "# dataset.variables['T2M'][0, 237:248, 135:150]\n",
    "variable_data = dataset.variables['T2M'][0, :,:]\n",
    "\n",
    "# Close the NetCDF file\n",
    "# dataset.close()\n",
    "# Plot the data\n",
    "plt.imshow(variable_data, origin='lower', cmap='viridis', extent=(longitude.min(), longitude.max(), latitude.min(), latitude.max()))\n",
    "plt.colorbar(label='Variable Unit')\n",
    "plt.xlabel('Longitude')\n",
    "plt.ylabel('Latitude')\n",
    "plt.title(f'Plot of {variable_name}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('variables provided in this netcdf are:', dataset.variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Statistics and Time Series Line Plots for the Methane Emission based on observations collected in 2020 and 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The bounding box should be passed to the geojson param as a geojson Feature or FeatureCollection\n",
    "# The following function generates statistics for the assigned parameter \n",
    "def generate_stats(item, geojson):\n",
    "    result = requests.post(\n",
    "        f\"{RASTER_API_URL}/cog/statistics\",\n",
    "        paragu={\"url\": item[\"assets\"][\"ch4-wetlands-emissions\"][\"href\"]},\n",
    "        json=geojson,\n",
    "    ).json()\n",
    "    return {\n",
    "        **result[\"properties\"],\n",
    "        \"datetime\": item[\"properties\"][\"datetime\"],\n",
    "    }"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the function above, we can generate the statistics for the area of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default value is to fetch the data for the past 2 years (2020, 2021). You can change the indices to fetch the values for years beyond that.\n",
    "stats = [generate_stats(item, louisiana_aoi) for item in items[:24]]\n",
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manipulating and cleaning the stats output from previous cell\n",
    "def clean_stats(stats_json) -> pd.DataFrame:\n",
    "    df = pd.json_normalize(stats_json)\n",
    "    df.columns = [col.replace(\"statistics.b1.\", \"\") for col in df.columns]\n",
    "    df[\"date\"] = pd.to_datetime(df[\"datetime\"])\n",
    "    return df\n",
    "\n",
    "\n",
    "df = clean_stats(stats)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering the stats for year 2020 and 2021\n",
    "df_2020_2021 = df[(df['date'].dt.year == 2020) | (df['date'].dt.year == 2021)]\n",
    "df_2020_2021['year'] = pd.to_datetime(df_2020_2021['datetime']).dt.year\n",
    "df_2020_2021['month'] = pd.to_datetime(df_2020_2021['datetime']).dt.month\n",
    "df_2020_2021"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the Data as a Time Series\n",
    "We can now plot the time-series of the wetland methane emissions for the state of Louisiana for the 2020-2021 (January - December) period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = {item[\"properties\"][\"datetime\"][:7]: item for item in items} \n",
    "fig = plt.figure(figsize=(20, 10))\n",
    "\n",
    "\n",
    "# Set the plot elements \n",
    "sns.lineplot(\n",
    "    df_2020_2021,\n",
    "    x = 'month', \n",
    "    y = 'sum',\n",
    "    hue= 'year',\n",
    "    palette='flare'\n",
    ")\n",
    "\n",
    "\n",
    "# Set the labels for the X and Y axis and assign a title for the plot \n",
    "# plt.legend()\n",
    "plt.xlabel(\"months\")\n",
    "plt.ylabel(\"CH4 emissions g/m2\")\n",
    "plt.title(\"CH4 emission Values for Louisiana for 2020 and 2021\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Statistics and Time Series Lineplots for MERRA2 Data in Year 2020, 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paragu={\n",
    "    'MERRA-2 T2M':\n",
    "        {'var':'T2M',\n",
    "        'cmap':'#000000',\n",
    "        'dir':merra_t2m_dir,\n",
    "        'nickname':'merra2_t2m',\n",
    "        'climdir':merra_t2m_clim_dir,\n",
    "        'climvar':'T2MMEAN'},\n",
    "    'MERRA-2 Surface Soil Moisture':\n",
    "        {'var':'GWETTOP',\n",
    "        'cmap':'#000000',\n",
    "        'dir':merra_soil_moisture_dir,\n",
    "        'nickname':'merra2_sm',\n",
    "        'climdir':merra_soil_moisture_clim_dir,\n",
    "        'climvar':'GWETTOP'},\n",
    "    'MERRA-2 Precipitation Rate':\n",
    "        {'var':'PRECTOT',\n",
    "        'cmap':'#000000',\n",
    "        'dir':merra_precip_rate_dir,\n",
    "        'nickname':'merra2_pr',\n",
    "        'climdir':merra_precip_rate_clim_dir,\n",
    "        'climvar':'PRECTOT'}\n",
    "}\n",
    "\n",
    "year=1991\n",
    "\n",
    "anomaly = 1\n",
    "param = ['MERRA-2 Precipitation Rate','MERRA-2 Surface Soil Moisture', 'MERRA-2 T2M' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_merra2_timeseries(year,focus,p,anomaly):\n",
    "    files = glob.glob(paragu[p]['dir']+'*.nc4') # change the year for which you want to read the files\n",
    "    if anomaly:\n",
    "        try:\n",
    "            clim_files = glob.glob(paragu[p]['climdir']+'*.nc4')\n",
    "        except:\n",
    "            print('Climatological mean files (climdir) not found for specified parameter.')\n",
    "            breakpoint()\n",
    "    month_labels = []\n",
    "    box_totals = []\n",
    "    month_field = []\n",
    "    dt = []\n",
    "    for i,f in enumerate(files):\n",
    "        data = nc.Dataset(f)\n",
    "        \n",
    "        #   Get bounding box\n",
    "        wlat = np.logical_and(\n",
    "            data['lat'][:] < boundaries[focus][3],\n",
    "            data['lat'][:] > boundaries[focus][2]\n",
    "        )\n",
    "        wlon = np.logical_and(\n",
    "            data['lon'][:] < boundaries[focus][1],\n",
    "            data['lon'][:] > boundaries[focus][0]\n",
    "        )\n",
    "\n",
    "        datestamp = f.split('.')[-2]\n",
    "        month = int(datestamp[-2::])\n",
    "\n",
    "        dt.append(datetime(year,month,1))\n",
    "        month_labels.append(datetime(year,month,1).strftime('%B'))\n",
    "\n",
    "        if anomaly:\n",
    "            #   Make sure you read the climatology for the right month (whichfile)\n",
    "            whichfile = [datetime(1991,month,1).strftime('%y%m')[1:] in f for f in clim_files] # Change the year for the data being used.\n",
    "            climdata = nc.Dataset(np.array(clim_files)[whichfile][0])\n",
    "            \n",
    "            #   Calculate sum (emissions) or mean (met paragu) over your bounding box\n",
    "            if 'LPJ' in p:\n",
    "                clim_box_total = np.nansum(climdata[paragu[p]['climvar']][0,wlat,wlon])\n",
    "                now_box_total = np.nansum(data[paragu[p]['var']][0,wlat,wlon])\n",
    "            elif 'MERRA' in p:\n",
    "                clim_box_total = np.nanmean(climdata[paragu[p]['climvar']][0,wlat,wlon])\n",
    "                now_box_total = np.nanmean(data[paragu[p]['var']][0,wlat,wlon])\n",
    "\n",
    "            #   Replace fill values with NaN \n",
    "            #   Otherwise differencing might give wild results? (Just be safe)\n",
    "            wfillclim = np.where(climdata[paragu[p]['climvar']][0,:,:] == climdata[paragu[p]['climvar']]._FillValue)\n",
    "            climfield = climdata[paragu[p]['climvar']][0,:,:]\n",
    "            climfield[wfillclim] = np.nan\n",
    "            wfillnow = np.where(data[paragu[p]['var']][0,:,:] == data[paragu[p]['var']]._FillValue)\n",
    "            nowfield = data[paragu[p]['var']][0,:,:]\n",
    "            nowfield[wfillnow] = np.nan\n",
    "\n",
    "            #   And finally, difference current month and long-term mean \n",
    "            box_totals.append(now_box_total - clim_box_total)\n",
    "            month_field.append(nowfield - climfield)\n",
    "            climdata.close()\n",
    "        else:\n",
    "            if 'LPJ' in p:\n",
    "                box_totals.append(np.nansum(data[paragu[p]['var']][0,wlat,wlon]))\n",
    "            elif 'MERRA' in p:\n",
    "                box_totals.append(np.nanmean(data[paragu[p]['var']][0,wlat,wlon]))\n",
    "            #   Replace fill values with NaN (otherwise maps are hard to read) \n",
    "            month_field.append(data[paragu[p]['var']][0,:,:])\n",
    "            wfill = np.where(month_field[-1] == data[paragu[p]['var']]._FillValue)\n",
    "            month_field[-1][wfill] = np.nan\n",
    "            #breakpoint()\n",
    "\n",
    "    #   Sort in case months are out of order\n",
    "    dti = np.argsort(dt)\n",
    "    month_labels = np.array(month_labels)[dti]\n",
    "    box_totals = np.array(box_totals)[dti]\n",
    "    month_field = np.array(month_field)[dti]\n",
    "\n",
    "    # print('mean ',np.nanmean(month_field))\n",
    "    # print('std ',np.nanstd(month_field))\n",
    "\n",
    "    data_return = {\n",
    "        'month_labels':month_labels,\n",
    "        'box_totals':box_totals,\n",
    "        'month_fields':month_field,\n",
    "        'units':data[paragu[p]['var']].units,\n",
    "        'lat':data['lat'][:],\n",
    "        'lon':data['lon'][:],\n",
    "        'mean':np.nanmean(month_field),\n",
    "        'std' : np.nanstd(month_field)\n",
    "    }\n",
    "    data.close()\n",
    "    return data_return \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of color codes assigned\n",
    "colors = ['#1B8FB5', '#16B573', '#C76B21']\n",
    "for i,p in enumerate(param):\n",
    "    \n",
    "    ts = get_merra2_timeseries(year,focus,p,anomaly)\n",
    "    print(f'Mean of variable {p} is {ts[\"mean\"]}')\n",
    "    print(f'Standard deviation of variable {p} is {ts[\"std\"]}')\n",
    "        \n",
    "    # if i == 0:\n",
    "    fig= plt.figure(figsize=(6,3))\n",
    "    ax = fig.add_subplot(1,1,1)\n",
    "\n",
    "    #breakpoint()\n",
    "    try:\n",
    "        ax.plot(\n",
    "            list(range(0,12)),\n",
    "            ts['box_totals'],\n",
    "            linestyle='-',\n",
    "            linewidth=2,\n",
    "            color=colors[i],\n",
    "            markersize=4,\n",
    "            marker='o',\n",
    "            label=p\n",
    "        )\n",
    "    except ValueError:\n",
    "        print('Double check that you have all twelve months of MERRA-2 data downloaded!')\n",
    "        print(paragu[p]['dir'])\n",
    "        breakpoint()\n",
    "\n",
    "    #   Construct plot title\n",
    "    title = '%s\\n%s Mean Monthly %s'%(focus,year,p)\n",
    "    if anomaly:\n",
    "        title+=' Anomaly' \n",
    "    if 'LPJ' in p:\n",
    "        title = title.replace('Mean','Total')\n",
    "    plt.title(title)\n",
    "    \n",
    "    plt.xticks(list(range(0,12)))\n",
    "    ax.set_xticklabels(ts['month_labels'],rotation=40,ha='right')\n",
    "\n",
    "\n",
    "    ax.legend(loc='best')\n",
    "    nickname = paragu[p]['nickname']\n",
    "    savename = 'box_summed_%s_%s_%s.png'% \\\n",
    "        (nickname,year,focus)\n",
    "    if anomaly:\n",
    "        ax.plot(list(range(-1,13)),np.zeros(14),linewidth=0.4)\n",
    "        savename = savename.replace('.png','_Anomaly.png')\n",
    "    ax.set_xlim(-1,12)\n",
    "    ax.set_ylim(min(ts['box_totals']),max(ts['box_totals']))     #   manual per parameter\n",
    "    plt.show()\n",
    "    plt.savefig(savename.split('/')[-1],dpi=300,bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
